#!/usr/bin/env python3
"""
APT Mirror Metrics Collector
Generated by Ansible - Do not edit manually
"""

import os
import time
import json
import psutil
import subprocess
from datetime import datetime
from prometheus_client import start_http_server, Gauge, Counter, Histogram
from threading import Thread

# Prometheus metrics
sync_duration = Histogram('apt_mirror_sync_duration_seconds', 'Time spent syncing mirror')
bandwidth_usage = Gauge('apt_mirror_bandwidth_bytes_per_second', 'Current bandwidth usage')
client_requests = Counter('apt_mirror_client_requests_total', 'Total client requests', ['client_ip', 'package'])
disk_usage = Gauge('apt_mirror_disk_usage_percent', 'Disk usage percentage')
mirror_size = Gauge('apt_mirror_size_bytes', 'Total mirror size in bytes')
package_count = Gauge('apt_mirror_package_count', 'Number of packages in mirror')

class MetricsCollector:
    def __init__(self):
        self.mirror_path = "{{ apt_mirror_base_path }}"
        self.metrics_port = {{ apt_mirror_metrics_port }}
        self.apache_log = "/var/log/apache2/apt-mirror-access.log"
        self.running = True
        
    def collect_disk_metrics(self):
        """Collect disk usage metrics"""
        try:
            usage = psutil.disk_usage(self.mirror_path)
            used_percent = (usage.used / usage.total) * 100
            disk_usage.set(used_percent)
            
            # Calculate mirror size
            mirror_dir = os.path.join(self.mirror_path, "mirror")
            if os.path.exists(mirror_dir):
                total_size = 0
                for root, dirs, files in os.walk(mirror_dir):
                    total_size += sum(os.path.getsize(os.path.join(root, f)) for f in files)
                mirror_size.set(total_size)
                
        except Exception as e:
            print(f"Error collecting disk metrics: {e}")
    
    def collect_package_metrics(self):
        """Collect package count metrics"""
        try:
            mirror_dir = os.path.join(self.mirror_path, "mirror")
            if os.path.exists(mirror_dir):
                count = 0
                for root, dirs, files in os.walk(mirror_dir):
                    count += len([f for f in files if f.endswith('.deb')])
                package_count.set(count)
        except Exception as e:
            print(f"Error collecting package metrics: {e}")
    
    def monitor_bandwidth(self):
        """Monitor bandwidth usage"""
        try:
            # Get network interface stats
            net_io = psutil.net_io_counters()
            bytes_sent = net_io.bytes_sent
            bytes_recv = net_io.bytes_recv
            
            time.sleep(1)
            
            net_io_new = psutil.net_io_counters()
            bytes_sent_new = net_io_new.bytes_sent
            bytes_recv_new = net_io_new.bytes_recv
            
            # Calculate bandwidth (bytes per second)
            bandwidth_out = bytes_sent_new - bytes_sent
            bandwidth_in = bytes_recv_new - bytes_recv
            total_bandwidth = bandwidth_out + bandwidth_in
            
            bandwidth_usage.set(total_bandwidth)
            
        except Exception as e:
            print(f"Error monitoring bandwidth: {e}")
    
    def track_sync_duration(self):
        """Track sync duration from log files"""
        try:
            sync_log = os.path.join(self.mirror_path, "var", "cron.log")
            if os.path.exists(sync_log):
                # Parse last sync duration from log
                with open(sync_log, 'r') as f:
                    lines = f.readlines()
                    
                # Look for sync completion messages
                for line in reversed(lines[-100:]):  # Check last 100 lines
                    if "sync completed" in line.lower():
                        # Extract duration if available
                        # This would need to be customized based on log format
                        break
                        
        except Exception as e:
            print(f"Error tracking sync duration: {e}")
    
    def parse_access_logs(self):
        """Parse Apache access logs for client metrics"""
        try:
            if not os.path.exists(self.apache_log):
                return
                
            # Get recent log entries
            result = subprocess.run(['tail', '-n', '100', self.apache_log], 
                                  capture_output=True, text=True)
            
            for line in result.stdout.split('\n'):
                if not line.strip():
                    continue
                    
                # Parse common log format
                parts = line.split('"')
                if len(parts) >= 2:
                    ip = parts[0].split()[0]
                    request = parts[1]
                    
                    # Extract package name from request
                    if '.deb' in request:
                        package_name = request.split('/')[-1].replace('.deb', '')
                        client_requests.labels(client_ip=ip, package=package_name).inc()
                        
        except Exception as e:
            print(f"Error parsing access logs: {e}")
    
    def run_collection_cycle(self):
        """Run one collection cycle"""
        self.collect_disk_metrics()
        self.collect_package_metrics()
        self.monitor_bandwidth()
        self.track_sync_duration()
        
        # Parse logs less frequently
        if int(time.time()) % 60 == 0:  # Every minute
            self.parse_access_logs()
    
    def start(self):
        """Start the metrics collection"""
        # Start Prometheus HTTP server
        start_http_server(self.metrics_port)
        print(f"Metrics server started on port {self.metrics_port}")
        
        while self.running:
            try:
                self.run_collection_cycle()
                time.sleep(10)  # Collect every 10 seconds
            except KeyboardInterrupt:
                self.running = False
                break
            except Exception as e:
                print(f"Collection error: {e}")
                time.sleep(30)  # Wait longer on error

if __name__ == "__main__":
    collector = MetricsCollector()
    collector.start()
