---
apache_airflow_version: "2.6.3"

apache_airflow_user: "airflow"
apache_airflow_group: "airflow"
apache_airflow_home: "/opt/airflow"
apache_airflow_python: "/usr/bin/python3"           # Change if using a venv
apache_airflow_venv_path: ""                        # e.g. /opt/airflow/venv (leave blank for system python)

# Executor Configuration
# Options: SequentialExecutor, LocalExecutor, CeleryExecutor, KubernetesExecutor
apache_airflow_executor: "CeleryExecutor"
apache_airflow_parallelism: 32                      # Max number of task instances that can run simultaneously
apache_airflow_max_active_runs_per_dag: 16          # Max number of active runs per DAG
apache_airflow_max_active_tasks_per_dag: 16         # Max number of active tasks per DAG

# Celery Executor Settings
apache_airflow_celery_worker_concurrency: 16        # Number of worker processes
apache_airflow_celery_flower_host: "0.0.0.0"
apache_airflow_celery_flower_port: 5555
apache_airflow_celery_flower_url_prefix: ""
apache_airflow_celery_result_backend: "{{ apache_airflow_database_url }}"

# Kubernetes Executor Settings (when using KubernetesExecutor)
apache_airflow_kubernetes_namespace: "airflow"
apache_airflow_kubernetes_airflow_configmap: "airflow-config"
apache_airflow_kubernetes_worker_container_repository: "apache/airflow"
apache_airflow_kubernetes_worker_container_tag: "{{ apache_airflow_version }}"
apache_airflow_kubernetes_delete_worker_pods: true
apache_airflow_kubernetes_delete_worker_pods_on_failure: false

# Metadata Database Configuration
apache_airflow_database_type: "postgresql"          # Options: sqlite, postgresql, mysql
apache_airflow_database_host: "localhost"
apache_airflow_database_port: 5432
apache_airflow_database_name: "airflow"
apache_airflow_database_user: "airflow"
apache_airflow_database_password: "airflow"
apache_airflow_database_url: >-
  {{ apache_airflow_database_type ~ '://' ~ apache_airflow_database_user ~ ':' ~ apache_airflow_database_password
     ~ '@' ~ apache_airflow_database_host ~ ':' ~ (apache_airflow_database_port | string)
     ~ '/' ~ apache_airflow_database_name }}

# Database Pool Settings
apache_airflow_database_pool_size: 5
apache_airflow_database_pool_recycle: 3600
apache_airflow_database_pool_pre_ping: true
apache_airflow_database_max_overflow: 10

# Message Broker Configuration (for CeleryExecutor)
# Options: redis, rabbitmq
apache_airflow_broker_type: "redis"
apache_airflow_broker_host: "localhost"
apache_airflow_broker_port: 6379
apache_airflow_broker_vhost: "0"
apache_airflow_broker_url: >-
  {{ apache_airflow_broker_type ~ '://' ~ apache_airflow_broker_host ~ ':' ~ (apache_airflow_broker_port | string)
     ~ '/' ~ apache_airflow_broker_vhost }}

# Multiple Scheduler Configuration (Airflow 2.0+)
apache_airflow_scheduler_instances: 1               # Number of scheduler instances for HA
apache_airflow_scheduler_ha_enabled: "{{ apache_airflow_scheduler_instances > 1 }}"
apache_airflow_scheduler_heartbeat_sec: 5
apache_airflow_scheduler_num_runs: -1               # -1 for continuous operation
apache_airflow_scheduler_processor_poll_interval: 1

# RBAC (Role-Based Access Control) Configuration
apache_airflow_rbac_enabled: true
apache_airflow_rbac_user_registration: false        # Disable self-registration in production
apache_airflow_rbac_user_registration_role: "Viewer"
apache_airflow_rbac_auth_type: "DB"                 # Options: DB, LDAP, OAUTH, etc.

# LDAP/Active Directory Integration
apache_airflow_ldap_enabled: false
apache_airflow_ldap_server: "ldap://{{ groups['openldap_servers'][0] if groups['openldap_servers'] is defined else 'localhost' }}"
apache_airflow_ldap_port: 389
apache_airflow_ldap_use_tls: true
apache_airflow_ldap_bind_user: "cn=admin,dc=example,dc=com"
apache_airflow_ldap_bind_password: "{{ vault_ldap_admin_password | default('admin') }}"
apache_airflow_ldap_basedn: "dc=example,dc=com"
apache_airflow_ldap_user_filter: "objectClass=*"
apache_airflow_ldap_user_name_attr: "uid"
apache_airflow_ldap_user_email_attr: "mail"
apache_airflow_ldap_group_filter: "objectClass=*"
apache_airflow_ldap_group_name_attr: "cn"
apache_airflow_ldap_group_member_attr: "memberUid"
apache_airflow_ldap_search_scope: "LEVEL"
apache_airflow_ldap_ca_cert: ""
apache_airflow_ldap_admin_groups: ["airflow_admins"]
apache_airflow_ldap_op_groups: ["airflow_operators"]
apache_airflow_ldap_user_groups: ["airflow_users"]
apache_airflow_ldap_viewer_groups: ["airflow_viewers"]

# SSL/TLS Configuration
apache_airflow_ssl_enabled: false
apache_airflow_ssl_cert_path: "{{ apache_airflow_home }}/ssl/airflow.crt"
apache_airflow_ssl_key_path: "{{ apache_airflow_home }}/ssl/airflow.key"
apache_airflow_ssl_ca_cert_path: "{{ apache_airflow_home }}/ssl/ca.crt"
apache_airflow_ssl_verify_certs: true
apache_airflow_ssl_use_step_ca: false               # Use step-ca for internal certificates
apache_airflow_ssl_use_letsencrypt: false           # Use Let's Encrypt for public certificates
apache_airflow_letsencrypt_domains:
  - "airflow.{{ ansible_domain | default('local') }}"
apache_airflow_letsencrypt_cert_path: "{{ apache_airflow_home }}/ssl"
apache_airflow_letsencrypt_cert_owner: "{{ apache_airflow_user }}"
apache_airflow_letsencrypt_cert_group: "{{ apache_airflow_group }}"

# Separate Worker Nodes Configuration
apache_airflow_worker_nodes_enabled: "{{ apache_airflow_executor == 'CeleryExecutor' }}"
apache_airflow_worker_autoscale: "16,4"             # max,min workers
apache_airflow_worker_prefetch_multiplier: 1
apache_airflow_worker_max_tasks_per_child: 1000
apache_airflow_worker_max_memory_per_child: 0       # 0 = unlimited

apache_airflow_systemd_units_enabled:
  - webserver
  - scheduler
  - worker                                    # Ignored if not CeleryExecutor
  - flower                                    # Celery monitoring (optional)

apache_airflow_fernet_key: "CHANGE_ME"                      # Vault this in production
apache_airflow_remote_logging: false
apache_airflow_elasticsearch_host: "http://elasticsearch:9200"
apache_airflow_logging_json: true

# Package dependencies based on executor
apache_airflow_executor_packages:
  CeleryExecutor: ['apache-airflow[celery,redis]', 'flower']
  KubernetesExecutor: ['apache-airflow[kubernetes]']
  LocalExecutor: ['apache-airflow[postgres]']
  SequentialExecutor: []

# Database client packages
apache_airflow_database_packages:
  postgresql: ['postgresql-client']
  mysql: ['mysql-client']
  sqlite: []

apache_airflow_extra_pip_packages: []               # Additional packages to install

# Installation options
apache_airflow_manage_database: true                # Whether to create database and user
apache_airflow_install_broker: false                # Whether to install message broker locally
apache_airflow_python_executable: "{{ apache_airflow_venv_path + '/bin/python' if apache_airflow_venv_path else apache_airflow_python }}"
