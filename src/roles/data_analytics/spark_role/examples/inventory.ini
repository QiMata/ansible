---
# Example inventory for Spark cluster deployment
# This shows how to organize hosts for different Spark components

[spark_masters]
spark-master-1.example.com ansible_host=10.0.1.10
spark-master-2.example.com ansible_host=10.0.1.11  # For HA setup

[spark_workers]
spark-worker-1.example.com ansible_host=10.0.1.20
spark-worker-2.example.com ansible_host=10.0.1.21
spark-worker-3.example.com ansible_host=10.0.1.22
spark-worker-4.example.com ansible_host=10.0.1.23

[spark_cluster:children]
spark_masters
spark_workers

[spark_cluster:vars]
# Common variables for all Spark nodes
ansible_user=ubuntu
ansible_ssh_private_key_file=~/.ssh/spark-cluster.pem
ansible_python_interpreter=/usr/bin/python3

# Network configuration
spark_role_master_host="{{ groups['spark_masters'][0] }}"
spark_role_master_url="spark://{{ groups['spark_masters'][0] }}:7077"

# Environment-specific settings
environment_name=production
datacenter=us-east-1
