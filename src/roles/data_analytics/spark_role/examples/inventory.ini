---
# Example inventory for Spark cluster deployment
# This shows how to organize hosts for different Spark components, including ZooKeeper for HA

[zookeeper_nodes]
zk1.example.com ansible_host=10.0.1.5
zk2.example.com ansible_host=10.0.1.6
zk3.example.com ansible_host=10.0.1.7

[zookeeper_nodes:vars]
zookeeper_client_port=2181

[spark_masters]
spark-master-1.example.com ansible_host=10.0.1.10
spark-master-2.example.com ansible_host=10.0.1.11  # For HA setup

[spark_workers]
spark-worker-1.example.com ansible_host=10.0.1.20
spark-worker-2.example.com ansible_host=10.0.1.21
spark-worker-3.example.com ansible_host=10.0.1.22
spark-worker-4.example.com ansible_host=10.0.1.23

[spark_cluster:children]
spark_masters
spark_workers

[spark_cluster:vars]
# Common variables for all Spark nodes
ansible_user=ubuntu
ansible_ssh_private_key_file=~/.ssh/spark-cluster.pem
ansible_python_interpreter=/usr/bin/python3

# Network configuration
spark_role_master_host="{{ groups['spark_masters'][0] }}"
spark_role_master_url="spark://{{ groups['spark_masters'][0] }}:7077"
spark_role_zookeeper_hosts="{{ groups['zookeeper_nodes'] | map('regex_replace', '^(.*)$', '\\1:' ~ (hostvars[groups['zookeeper_nodes'][0]].zookeeper_client_port | default(2181))) | join(',') }}"

# Environment-specific settings
environment_name=production
datacenter=us-east-1
